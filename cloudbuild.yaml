# cloudbuild.yaml
# CI/CD for data ingestion Cloud Function + Pub/Sub + BigQuery wiring.

substitutions:
  # Using a known stable SDK version
  _SDK_TAG: '488.0.0-stable'
  _GCP_REGION: 'us-central1'
  _TRIGGER_TOPIC: 'run-daily-ingestion'
  _PUB_SUB_TOPIC: 'daily-bars-raw'
  _BIGQUERY_DATASET: 'quant_data'
  _BIGQUERY_TABLE: 'daily_bars_raw'
  _BIGQUERY_SUB_ID: 'daily-bars-raw-bq-sub'

steps:
# STEP 0: Enable required APIs (idempotent).
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:${_SDK_TAG}'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      gcloud services enable \
        cloudfunctions.googleapis.com \
        eventarc.googleapis.com \
        run.googleapis.com \
        pubsub.googleapis.com \
        bigquery.googleapis.com \
        secretmanager.googleapis.com \
        --project=${PROJECT_ID}

# Step 1: Ensure Pub/Sub topics exist
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:${_SDK_TAG}'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      # If 'describe' fails, then run 'create'
      gcloud pubsub topics describe run-daily-ingestion || gcloud pubsub topics create run-daily-ingestion
      gcloud pubsub topics describe daily-bars-raw || gcloud pubsub topics create daily-bars-raw

# Step 2: Ensure BigQuery resources exist
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:${_SDK_TAG}'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      # Check/Create Dataset
      bq show quant_data || bq mk -d quant_data
      
      # Check/Create Table
      # IMPORTANT: Verify the path below. Assuming 'schema.json' is in the root of the repository.
      bq show quant_data.daily_bars_raw || bq mk -t quant_data.daily_bars_raw schema.json

# Step 3: Ensure Pub/Sub subscription exists
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:${_SDK_TAG}'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      # Check/Create Subscription
      gcloud pubsub subscriptions describe ${_BIGQUERY_SUB_ID} || \
      gcloud pubsub subscriptions create ${_BIGQUERY_SUB_ID} \
        --topic=${_PUB_SUB_TOPIC} \
        --bigquery-table=${PROJECT_ID}:${_BIGQUERY_DATASET}.${_BIGQUERY_TABLE}

# STEP 4: Grant DEPLOY-TIME permissions to the Cloud Build Service Account.
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:${_SDK_TAG}'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      # The Cloud Build SA needs to act as the Function's SA during deployment.
      gcloud iam service-accounts add-iam-policy-binding \
        mjblank2@quant-setup.iam.gserviceaccount.com \
        --member="serviceAccount:${PROJECT_NUMBER}@cloudbuild.gserviceaccount.com" \
        --role="roles/iam.serviceAccountUser" \
        --project=${PROJECT_ID}
      
      echo "Waiting for IAM propagation..."
      sleep 5

      # The Cloud Build SA needs the Cloud Run Admin role to create the underlying service for a Gen2 function.
      gcloud projects add-iam-policy-binding ${PROJECT_ID} \
        --member="serviceAccount:${PROJECT_NUMBER}@cloudbuild.gserviceaccount.com" \
        --role="roles/run.admin"

# STEP 5: Grant RUNTIME permissions to the Function's Service Account.
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:${_SDK_TAG}'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      # The Function's SA needs permission to publish to the Pub/Sub topic.
      gcloud projects add-iam-policy-binding ${PROJECT_ID} \
        --member="serviceAccount:mjblank2@quant-setup.iam.gserviceaccount.com" \
        --role="roles/pubsub.publisher"

      echo "Waiting for IAM propagation..."
      sleep 5

      # The Function's SA needs permission to access secrets.
      gcloud projects add-iam-policy-binding ${PROJECT_ID} \
        --member="serviceAccount:mjblank2@quant-setup.iam.gserviceaccount.com" \
        --role="roles/secretmanager.secretAccessor"

# STEP 6: Deploy the Gen2 Cloud Function
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:${_SDK_TAG}'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      echo "All permissions granted. Attempting final deployment..."
      
      gcloud functions deploy ingest-daily-data \
        --gen2 \
        --region=${_GCP_REGION} \
        --runtime=python311 \
        --source=./data_ingestion \
        --trigger-topic=${_TRIGGER_TOPIC} \
        --entry-point=ingest_daily_data \
        --service-account=mjblank2@quant-setup.iam.gserviceaccount.com \
        --set-env-vars="GCP_PROJECT_ID=${PROJECT_ID},PUB_SUB_TOPIC=${_PUB_SUB_TOPIC},ALPACA_SECRET_NAME=projects/${PROJECT_NUMBER}/secrets/alpaca-api-keys/versions/latest" \
        --verbosity=info

# --- Build Options ---
options:
  logging: CLOUD_LOGGING_ONLY
